---
title: 吴恩达机器学习笔记 - 多变量梯度下降 & 正规方程 & Octrave 编程
date: 2020-03-24 20:00:00
---
# 吴恩达机器学习笔记 - 多变量梯度下降 & 正规方程 & Octave 编程
***
> 版权声明：本文为 {{ site.name }} 原创文章，可以随意转载，但必须在明确位置注明出处！

## 一、多变量梯度下降

### 1.1 多维特征

上篇文章我们介绍了第一个机器学习算法，即通过房屋面积来预测价格，这个问题中只使用一个输入特征房屋面积，可现实生活中要解决的问题通常都含有多个特征，并且用多个特征训练出的模型准确度更高，那么如何机器学习算法如何处理多个特征的输入呢？

我们还用预测房价的例子，不过这次要增加另外 3 个特征，卧室数量，房屋楼层，房屋年龄：

<div  align="center">
<img src="http://www.ai-start.com/ml2014/images/591785837c95bca369021efa14a8bb1c.png"/>
</div>

这样一来，我们就有了 4 个输入特征了，特征多了，表示的方法也要升升级了：

- $n$：输入特征的数量，即特征矩阵列数，也即特征向量的维度
- ${x^{\left( i \right)}}$：训练集中第 $i$ 个实例向量，就是特征矩阵的第 $i$ 行，比如列向量 ${x}^{(2)}\text{=}\begin{bmatrix} 1416\\ 3\\ 2\\ 40 \end{bmatrix}$

- ${x_j}^{\left( i \right)}$：训练集中第 $i$ 个实例的第 $j$ 个特征，比如 $x_2^{\left( 2 \right)}=3$



特征数量增加了，之前的假设函数肯定也需要修改，要把增加的特征变量和参数加上：$h_{\theta}\left( x \right)={\theta_{0}}+{\theta_{1}}{x_{1}}+{\theta_{2}}{x_{2}}+...+{\theta_{n}}{x_{n}}$，虽然这样表示没问题，但是却不方便利用向量来计算，因为参数 $\theta$ 有 n + 1 个，但 $x$ 只有 n 个，那怎么办呢？

很简单，我们额外增加一个 ${x_0}=1$，则上式变为：$h_{\theta} \left( x \right)={\theta_{0}}{x_{0}}+{\theta_{1}}{x_{1}}+{\theta_{2}}{x_{2}}+...+{\theta_{n}}{x_{n}}$，这样一来就可以写成向量相乘的形式：$h_{\theta} \left( x \right)={\theta^{T}}X$，你可能要问了为何要写成向量的形式？

因为 2 点：

- 使用向量方便程序编写，一句计算特征向量的代码就可以同时计算多个输入参数，因为一个特征向量中包含所有输入参数
- 使用向量方便算法执行，梯度下降算法要求参数同时更新，如果不使用向量，那更新起来非常麻烦。

通过增加一个维度 $x_0 = 1$，最终训练集的特征矩阵的大小为：$m * (n + 1)$，其中 m 为行数，n + 1 为列数。通过特征向量的表示，我们就可以将特征矩阵的每一行作为一个特征向量（就是特征组成的向量 =_=），并用它们来训练机器学习算法。

以上就是我对多维特征作为机器学习算法输入的一些理解，非常感谢吴恩达老师的公开课 ^_^。

## 二、特征和多项式回归







## 三、正规方程法







## 四、Octave 编程基础



























<div  align="center">
<img src="https://dlonng.com/images/xxx/xxx.png"/>
</div>

> {{ site.prompt }}

<div  align="center">
<img src="https://dlonng.com/images/wechart.jpg" width = "200" height = "200"/>