---
title: 从 0 开始机器学习 - 什么是正规方程法？
date: 2020-03-30 20:00:00
---
# 从 0 开始机器学习 - 什么是正规方程法？
***
> 版权声明：本文为 {{ site.name }} 原创文章，可以随意转载，但必须在明确位置注明出处！

## 一、正规方程法

### 1.1 基本原理

之前介绍的梯度下降法求代价函数最小值用的是迭代的方法，但还记得高中学过的求函数极值的方法吗？就是令待求函数的导函数等于零，求出的变量 x 就是函数取最小值的位置。

这里介绍的正规方程法其实就是令代价函数对每个变量 $\theta_i$ 的偏导数等于 0，以此来求每个最优的 $\theta_i$：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/AndrewNg_ML/normal_equation.png)

上图就是正规方程求最优参数的原理，例子用的代价函数还是平方误差，关键步骤是对每个 $ j $ ，令 $\theta_j$ 的偏导数为 0，求出最后的 $\theta_0, \theta_1, \theta_2, ..., \theta_n$。

上面的原理最终可以用一个矩阵公式来求解：


$$
\theta ={(X^TX)^{-1}}{X^T}y
$$


$X$ 表示输入的特征矩阵，$y$ 表示每个训练实例的结果组成的向量，$\theta$ 表示待求的参数，下面来看一个实际的例子。

### 1.2 用正规方程预测房价

我们还以预测房价为例，下面用正规方程法来求解：

![](https://dlonng.oss-cn-shenzhen.aliyuncs.com/AndrewNg_ML/normal_horse.png)

假设我们有 4 个训练实例，那么特征矩阵 $X$ 就是 4 X 4，而 $y$ 就是每个房屋实例真实的房价，将这两个矩阵带入正规方程中就可以求出参数 $\theta$ 了：

![](http://www.ai-start.com/ml2014/images/b62d24a1f709496a6d7c65f87464e911.jpg)

原理搞清楚后，实际的代码其实就一行，毕竟是解方程，计算机很擅长这件事情：

```python
import numpy as np
    
def normalEqn(X, y):
  # X.T@X 等价于 X.T.dot(X)
  theta = np.linalg.inv(X.T@X)@X.T@y 
  
  return theta
```

### 1.3 正规方程的 2 个缺陷

对于不可逆（奇异或退化）的矩阵 $X^TX$，正规方程是不能使用的，但这种不可逆的情况很少发生，导致这个矩阵不可逆的情况主要有以下 2 种（就是基本的线代不可逆理论）：

- 存在重复的特征变脸：用房价例子来解释就是说比如有一个特征 $x_1$ 以英尺来表示房屋尺寸，而另一个特征 $x_2$ 以米为尺寸，但是我们知道 1 米 = 3.28 英尺，所以这两个特征向量可以互相线性表示（相当于重复），则矩阵不可逆，解决方法就是找到删除重复的特征。
- 特征数量大于训练实例数量：比如有 100 个特征变量，但是只有 10 个训练数据实例，即矩阵的行数小于列数，这样的情况也会导致矩阵不可逆，不过这种情况可以使用正则化技术解决，下次介绍吧。

### 3.4 正规方程 VS 梯度下降

我们已经学习了这两种方法，其中正规方程主要适用于特征变量数量不太大时（n < 10000），而梯度下降法在特征数量很多时效果比较好，下面是这两种方法的详细比较：

|         正规方程          |        梯度下降         |
| :-----------------------: | :---------------------: |
|          不需要           | 需要选择学习率 $\alpha$ |
|       一次运算得出        |      需要多次迭代       |
| 特征数量 < 10000 可以接受 |  特征数量较大也能适用   |
|   只适用于线性回归模型    |     适用于各种模型      |


> {{ site.prompt }}

<div  align="center">
<img src="https://dlonng.com/images/wechart.jpg" width = "200" height = "200"/>